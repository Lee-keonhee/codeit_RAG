import os, json, yaml
from typing import Dict, List, Any, Optional
from data_loader import load_documents
from preprocessor import process_all_documents
from embedder import embed_chunks
from vector_store import create_vector_store, save_vector_store, load_vector_store
from retriever import retrieve
from generator_test import RAGGenerator

class RAGPipeline:
    """
    ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì´ê´„
    build_index() â†’ ë¬¸ì„œ â†’ ì²­í¬ â†’ ì„ë² ë”© â†’ VectorStore ì €ì¥
    query() â†’ ê²€ìƒ‰ + LLM ë‹µë³€
    """
    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
        self.top_k = self.config.get('retrieval', {}).get('top_k', 5)
        self.vector_store_path = self.config.get('paths', {}).get('vector_store_dir', '../vector_store')
        self.vector_store = None # ë¡œë“œëœ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì €ì¥í•  ë³€ìˆ˜
        
        self.generator_test = RAGGenerator(
            model=self.config.get('openai', {}).get('chat_model', 'gpt-5-mini'),
            response_type=self.config.get("openai", {}).get("response_type", "detailed")
        )

    def _load_config(self, config_path: Optional[str]):
        if config_path is None:
            return {}

        if not os.path.exists(config_path):
            abs_path = os.path.abspath(config_path)
            raise FileNotFoundError(f"Config íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {abs_path}")

        # YAML or JSON ìë™ íŒë³„
        ext = os.path.splitext(config_path)[1].lower()

        if ext in [".yaml", ".yml"]:
            with open(config_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        elif ext == ".json":
            with open(config_path, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            raise ValueError("Config íŒŒì¼ì€ .yaml/.yml/.json ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

    def build_index(self, doc_folder: str = 'data_dir', metadata_path: str = 'metadata_path'):
        try:
            index_file_path = os.path.join(self.vector_store_path, 'index.faiss')

            # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„
            if os.path.exists(index_file_path):
                print(f"ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ: {self.vector_store_path}")
                self.vector_store = load_vector_store(self.vector_store_path) 
                return

            # ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥
            print("ìƒˆ ì¸ë±ìŠ¤ ìƒì„±")
            
            # config ë”•ì…”ë„ˆë¦¬ì—ì„œ ê²½ë¡œ í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            documents = load_documents(self.config['paths'][doc_folder], self.config['paths'][metadata_path])
            all_chunks = process_all_documents(documents, self.config)
            all_chunks = embed_chunks(all_chunks)

            self.vector_store = create_vector_store(all_chunks)
            save_vector_store(self.vector_store, self.vector_store_path)
            print(f"ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì™„ë£Œ: {self.vector_store_path}")

        except Exception as e:
            print(f"ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def load_index(self):
        store_dir = self.vector_store_path

        if not os.path.exists(store_dir):
            raise FileNotFoundError(f"VectorStore ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {store_dir}")

        print(f"VectorStore ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {store_dir}")
        self.vector_store = load_vector_store(store_dir)

    def query(self, question: str, filters: Optional[Dict] = None):
        """
        ì „ì²´ RAG Query ì²˜ë¦¬
        """
        if self.vector_store is None:
            self.load_index()
            
        print("\nê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
        
        retrieved_chunks = retrieve(
            question,
            self.vector_store,
            self.top_k,
            filters
        )
        print(f"    âœ ê²€ìƒ‰ëœ ì²­í¬: {len(retrieved_chunks)}ê°œ")

        
        print("LLM ë‹µë³€ ìƒì„± ì¤‘...")
        
        llm_result = self.generator_test.generate(
            query=question,
            retrieved_chunks=retrieved_chunks,
            use_history=True
        )
        
        return {
            "answer": llm_result["answer"],
            "sources": llm_result["sources"],
            "retrieved_chunks": retrieved_chunks,
            "metadata": llm_result["metadata"]
        }

def get_filter_from_user():
    print("ê²€ìƒ‰ì— ì‚¬ìš©í•  ë©”íƒ€ë°ì´í„° ê°’ì„ ì…ë ¥í•˜ì„¸ìš”(ì—”í„°ì‹œ ê±´ë„ˆëœ€)")
    filters = {}
    filters['ì‚¬ì—…ëª…'] = input("ì‚¬ì—…ëª…: ") or None
    filters['ì‚¬ì—… ê¸ˆì•¡'] = parse_numeric_filter(input("ì‚¬ì—… ê¸ˆì•¡: ")) or None
    filters['ë°œì£¼ ê¸°ê´€'] = input("ë°œì£¼ ê¸°ê´€: ") or None
    filters['íŒŒì¼ëª…'] = input("íŒŒì¼ëª…: ") or None
    filters['ì‚¬ì—… ìš”ì•½'] = input("ì‚¬ì—… ìš”ì•½: ") or None

def parse_numeric_filter(user_input: str):
    """
    ì‚¬ìš©ì ë¬¸ìì—´ (ì˜ˆ: '>20000') -> dict í˜•íƒœ (ì˜ˆ: {'$gt': 20000})
    """
    user_input = user_input.strip().replace(' ', '')
    op_map = {
        '>=': '$gte',
        '<=': '$lte',
        '>': '$gt',
        '<': '$lt',
        '=': '$eq'
    }
    # ìš°ì„  >=, <= ê°™ì€ ê¸´ ì—°ì‚°ìë¶€í„° ì²´í¬
    for symbol, mongo_op in op_map.items():
        if user_input.startswith(symbol):
            num_part = user_input[len(symbol):]
            try:
                value = int(num_part)
                return {mongo_op: value}
            except ValueError:
                return None  # ìˆ«ìë¡œ ë³€í™˜ ì‹¤íŒ¨ ì‹œ
    # ìˆ«ìë§Œ ì…ë ¥í•œ ê²½ìš° eqë¡œ ì²˜ë¦¬
    if user_input.isdigit():
        return {'$eq': int(user_input)}
    return None

# -----------------------------
# TEST
# -----------------------------
if __name__ == "__main__":
    try:
        pipe = RAGPipeline(config_path="../config/config_test.yaml")
        
        user_filters = get_filter_from_user() #ë©”íƒ€ë°ì´í„° í•„í„° UI ë„£ëŠ”ê±° ì•„ë‹Œì´ìƒ ê¼¬ë¦¬ ë¬´ëŠ” ì§ˆë¬¸ì—ì„œ ë¶ˆí¸
        while True:
            question = input("ì§ˆë¬¸(q ì…ë ¥ì‹œ ì¢…ë£Œ): ")
            if question.lower() == 'q':
                break
                
            response = pipe.query(question, user_filters)
            
            print("\n====== ê²°ê³¼ ======")
            print("ğŸ¤– AI:", response["answer"])
            print("ì°¸ê³ ë¬¸ì„œ:", response["sources"])
    
    except FileNotFoundError as e:
        print(f"\n[í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜] {e}. íŒŒì¼ì„ í™•ì¸í•˜ê±°ë‚˜ Mock ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì‹­ì‹œì˜¤.")
    except Exception as e:
        print(f"\n[í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜] ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ ë°œìƒ: {e}")